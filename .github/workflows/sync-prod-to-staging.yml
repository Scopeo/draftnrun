name: Sync Prod DB to Staging

on:
  workflow_dispatch:
    inputs:
      force_sync:
        description: "Force full data + Qdrant sync even if TTL cache is valid"
        required: false
        default: false
        type: boolean

jobs:
  sync-database:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Save replica counts and scale down pods
        id: scale_down
        uses: appleboy/ssh-action@master
        with:
          host: ${{ secrets.EC2_HOST_K8S_STAGING }}
          username: ec2-user
          key: ${{ secrets.SSH_PRIVATE_KEY }}
          port: 22
          script: |
            set -e
            NS="ada-staging"
            STATE_FILE="/tmp/ada-sync-replicas-${{ github.run_id }}.txt"
            
            # Save current replica counts
            echo "üíæ Saving current replica counts..."
            kubectl get deployment -n ${NS} -o json | \
              jq -r '.items[] | "\(.metadata.name)=\(.spec.replicas)"' > "$STATE_FILE"
            
            cat "$STATE_FILE"
            
            # Scale down with error handling
            echo "‚¨áÔ∏è Scaling down all deployments..."
            if ! kubectl scale deployment --all -n ${NS} --replicas=0; then
              echo "‚ùå Failed to scale down deployments"
              rm -f "$STATE_FILE"
              exit 1
            fi
            
            kubectl wait --for=delete pod -l app -n ${NS} --timeout=300s || {
              echo "‚ö†Ô∏è Warning: Some pods did not terminate within timeout"
            }

      - name: Sync data from prod to staging (with TTL cache)
        id: sync
        continue-on-error: true
        uses: appleboy/ssh-action@master
        with:
          host: ${{ secrets.EC2_HOST_K8S_STAGING }}
          username: ec2-user
          key: ${{ secrets.SSH_PRIVATE_KEY }}
          port: 22
          command_timeout: 15m
          script: |
            NS="ada-staging"
            STATE_FILE="/tmp/ada-sync-replicas-${{ github.run_id }}.txt"
            
            # Clone/update repo to get latest sync scripts
            REPO_DIR="/tmp/draftnrun-sync"
            if [ -d "$REPO_DIR" ]; then
              cd "$REPO_DIR"
              git fetch origin
              git checkout ${{ github.sha }}
            else
              git clone https://github.com/${{ github.repository }}.git "$REPO_DIR"
              cd "$REPO_DIR"
              git checkout ${{ github.sha }}
            fi

            FORCE_SYNC_FLAG=""
            if [ "${{ inputs.force_sync }}" = "true" ]; then
              FORCE_SYNC_FLAG="--force-sync"
            fi

            echo "üì¶ Running sync script from temporary directory..."
            
            # Run sync and capture output
            if ./scripts/copy_data/sync_data.sh \
              --source-db-url "${{ secrets.PROD_DB_URL }}" \
              --source-ingestion-db-url "${{ secrets.PROD_INGESTION_DB_URL }}" \
              --target-db-url "${{ secrets.STAGING_DB_URL }}" \
              --target-ingestion-db-url "${{ secrets.STAGING_INGESTION_DB_URL }}" \
              --source-qdrant-url "${{ secrets.PROD_QDRANT_CLUSTER_URL }}" \
              --source-qdrant-key "${{ secrets.PROD_QDRANT_API_KEY }}" \
              --target-qdrant-url "${{ secrets.STAGING_QDRANT_CLUSTER_URL }}" \
              --target-qdrant-key "${{ secrets.STAGING_QDRANT_API_KEY }}" \
              $FORCE_SYNC_FLAG 2>&1 | tee /tmp/sync-output.log; then
              
              # Check if sync was actually performed or skipped
              if grep -qi "skip\|cache.*valid\|already.*synced" /tmp/sync-output.log; then
                echo "‚è≠Ô∏è Sync skipped due to valid TTL cache"
                echo "SKIPPED" > "${STATE_FILE}.sync_status"
                exit 0
              else
                echo "‚úÖ Sync completed successfully"
                echo "SYNCED" > "${STATE_FILE}.sync_status"
                exit 0
              fi
            else
              echo "‚ùå Sync failed"
              echo "FAILED" > "${STATE_FILE}.sync_status"
              exit 1
            fi

      - name: Run migrations and seed as Jobs
        if: success()
        continue-on-error: true
        uses: appleboy/ssh-action@master
        with:
          host: ${{ secrets.EC2_HOST_K8S_STAGING }}
          username: ec2-user
          key: ${{ secrets.SSH_PRIVATE_KEY }}
          port: 22
          command_timeout: 15m
          script: |
            set -e
            NS="ada-staging"
            STATE_FILE="/tmp/ada-sync-replicas-${{ github.run_id }}.txt"
            
            # Check if sync was actually performed
            if [ -f "${STATE_FILE}.sync_status" ]; then
              SYNC_STATUS=$(cat "${STATE_FILE}.sync_status")
              if [ "$SYNC_STATUS" = "SKIPPED" ]; then
                echo "‚è≠Ô∏è Skipping migrations - sync was not performed"
                exit 0
              fi
            fi

            # Get the current image from the deployment
            IMAGE=$(kubectl get deployment/ada-api -n ${NS} -o jsonpath='{.spec.template.spec.containers[0].image}')

            echo "üóÑÔ∏è Running migrations as Kubernetes Job..."
            kubectl create job db-migrate -n ${NS} \
              --image=${IMAGE} \
              --from=deployment/ada-api \
              -- alembic -c ada_backend/database/alembic.ini upgrade head

            kubectl wait --for=condition=complete job/db-migrate -n ${NS} --timeout=300s
            kubectl delete job db-migrate -n ${NS}

            echo "üå± Running seed as Kubernetes Job..."
            kubectl create job db-seed -n ${NS} \
              --image=${IMAGE} \
              --from=deployment/ada-api \
              -- python -m ada_backend.database.seed_db

            kubectl wait --for=condition=complete job/db-seed -n ${NS} --timeout=300s
            kubectl delete job db-seed -n ${NS}

            echo "‚úÖ Database migrations and seed complete!"

      - name: Scale up pods to original replica counts
        if: always()
        uses: appleboy/ssh-action@master
        with:
          host: ${{ secrets.EC2_HOST_K8S_STAGING }}
          username: ec2-user
          key: ${{ secrets.SSH_PRIVATE_KEY }}
          port: 22
          script: |
            set -e
            NS="ada-staging"
            STATE_FILE="/tmp/ada-sync-replicas-${{ github.run_id }}.txt"
            
            if [ ! -f "$STATE_FILE" ]; then
              echo "‚ö†Ô∏è Warning: Replica state file not found, using defaults"
              kubectl scale deployment/ada-api -n ${NS} --replicas=1 || true
              kubectl scale deployment/ada-ingestion-worker -n ${NS} --replicas=1 || true
              kubectl scale deployment/ada-webhook-worker -n ${NS} --replicas=1 || true
              kubectl scale deployment/ada-scheduler -n ${NS} --replicas=1 || true
            else
              echo "‚¨ÜÔ∏è Scaling back to original replica counts..."
              while IFS='=' read -r deployment replicas; do
                echo "Scaling ${deployment} to ${replicas} replicas"
                kubectl scale deployment/${deployment} -n ${NS} --replicas=${replicas} || true
              done < "$STATE_FILE"
              
              # Cleanup state files
              rm -f "$STATE_FILE" "${STATE_FILE}.sync_status" /tmp/sync-output.log
            fi
            
            echo "‚úÖ Pods scaled back up!"
