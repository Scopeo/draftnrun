name: llm-services-ci

on:
  workflow_dispatch:
  pull_request:
    branches:
      - main
    paths:
      - "engine/llm_services/**"
      - "components/types.py"
      - "components/utils.py"
      - "tests/llm_services/**"
      - "engine/trace/**"

concurrency:
  group: llm-services-ci
  cancel-in-progress: false

jobs:
  ci-pipeline:
    runs-on: ubuntu-latest
    timeout-minutes: 10

    strategy:
      matrix:
        python-version: [3.11]

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          lfs: true

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ matrix.python-version }}

      - name: Install uv
        uses: astral-sh/setup-uv@v4
        with:
          version: "latest"

      - name: Install dependencies
        run: uv sync

      - name: Run LLM services tests
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          COHERE_API_KEY: ${{ secrets.COHERE_API_KEY }}
          MISTRAL_API_KEY: ${{ secrets.MISTRAL_API_KEY }}
          GOOGLE_API_KEY: ${{ secrets.GOOGLE_API_KEY }}
          GOOGLE_BASE_URL: https://generativelanguage.googleapis.com/v1beta/openai/
          CEREBRAS_API_KEY: ${{ secrets.CEREBRAS_API_KEY }}
          CEREBRAS_BASE_URL: https://api.cerebras.ai/v1
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
          ANTHROPIC_BASE_URL: https://api.anthropic.com/v1/messages
          # Minimal env vars for tests
          ADA_DB_URL: "sqlite:///:memory:"
          FERNET_KEY: "AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA="
        run: |
          uv run pytest -q tests/llm_services