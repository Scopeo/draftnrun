# Chatbot Core
OPENAI_API_KEY=sk-xxxx
MISTRAL_API_KEY=xxxx

# Cohere
COHERE_API_KEY=xxxxx

#SNOWFLAKE
SNOWFLAKE_PASSWORD = xxxx
SNOWFLAKE_ACCOUNT = xxxx
SNOWFLAKE_USER = xxxx

#QDRANT
QDRANT_API_KEY=secret_api_key
QDRANT_CLUSTER_URL=http://localhost:6333

LLM_BASE_URL = xxxxx
LLM_API_KEY = xxxxx
LLM_MODEL_NAME = xxxx
EMBEDDING_MODEL_NAME = xxxx

DB_URL = xxxxx

#GEMINI_API_KEY (need to run ingestion task)
GOOGLE_BASE_URL=https://generativelanguage.googleapis.com/v1beta/openai/
GOOGLE_API_KEY=xxx

# E2B Code Sandbox
E2B_API_KEY=your_e2b_api_key_here

# Encryption Key for Storing Sensitive Data
# Generate a Fernet key using:
# python -c "from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())"
FERNET_KEY=your-encryption-key-here

# Backend Secret Key for JWT Signing
# Generate a secure key using:
# python -c "import secrets; print(secrets.token_hex(32))"
BACKEND_SECRET_KEY=your-secure-backend-key

# RELOAD_SCOPEO_AGENTS_BACKEND: This is a flag to watch for changes in the
# ada_backend and reload the app, useful for development.
RELOAD_SCOPEO_AGENTS_BACKEND=False


# Supabase credentials
SUPABASE_PROJECT_URL=http://localhost:54321
SUPABASE_SERVICE_ROLE_SECRET_KEY=xxxx
SUPABASE_PROJECT_KEY=xxxxx

SUPABASE_USERNAME=xxx
SUPABASE_PASSWORD=xxx
SUPABASE_BUCKET_NAME=ada-backend

#FOR INGESTION QUEUE
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_PASSWORD=redis_password
REDIS_QUEUE_NAME=ada_ingestion_queue
MAX_CONCURRENT_INGESTIONS=2

# ADA Database Configuration
# Choose either SQLite or PostgreSQL

# For SQLite, set ADA_DB_URL (required):
#ADA_DB_DRIVER=sqlite
#ADA_DB_URL=sqlite:///ada_backend/database/ada_backend.db

# For PostgreSQL, set these parameters:
# ADA_DB_DRIVER=postgresql
# ADA_DB_HOST=localhost
# ADA_DB_PORT=5432
# ADA_DB_USER=your_user
# ADA_DB_PASSWORD=your_password
# ADA_DB_NAME=ada_backend

ADA_DB_URL=postgresql://postgres:ada_password@localhost:5432/ada_backend

# URL to run the backend app 
ADA_URL=http://localhost:8000

# If you want to connect to the backend console and the docs
# go to ADA_URL/admin or ADA_URL/docs and enter those username/password
ADMIN_USERNAME=your-admin-username
ADMIN_PASSWORD=your-admin-password


# For Ingestion, set INGESTION_DB_URL (required):
INGESTION_DB_URL=postgresql://postgres:ada_password@localhost:5432/ada_ingestion

# For Traces, set TRACES_DB_URL (required):
TRACES_DB_URL=postgresql://postgres:ada_password@localhost:5432/ada_traces

# For Ingestion, set also the API_KEY 
# To build them, run this:
#python -c "from ada_backend.services.api_key_service import _generate_api_key, _hash_key; key = _generate_api_key(); print('INGESTION_API_KEY =', key); print('INGESTION_API_KEY_HASHED =', _hash_key(key))"

INGESTION_API_KEY=xxxx
INGESTION_API_KEY_HASHED=xxxx

# PGADMIN
PGADMIN_DEFAULT_EMAIL=
PGADMIN_DEFAULT_PASSWORD=
PGADMIN_PORT=5050

# S3 CREDENTIALS FOR INGESTION
S3_ENDPOINT_URL=http://localhost:8333
S3_ACCESS_KEY_ID=your_s3_access_key_id
S3_SECRET_ACCESS_KEY=your_s3_secret_access_key
S3_BUCKET_NAME=s3-backend
S3_REGION_NAME=us-east-1

GOOGLE_CLIENT_SECRET=xxxx
GOOGLE_CLIENT_ID=XXXX

# OBSERVABILITY STACK CONFIGURATION
# Grafana Security - IMPORTANT: Change these values!
GF_SECURITY_ADMIN_USER=admin
GF_SECURITY_ADMIN_PASSWORD=admin

# Observability Endpoints (localhost for same-machine deployment)
TEMPO_ENDPOINT=http://localhost:4318/v1/traces
PROMETHEUS_URL=http://localhost:9090
GRAFANA_URL=http://localhost:3000

# Enable/disable observability stack (Prometheus HTTP metrics + Tempo tracing)
# Set to true to enable performance monitoring (requires observability stack running)
# Set to false to run backend without observability dependencies
ENABLE_OBSERVABILITY_STACK=true

# Number of pages to detect document type
NUMBER_OF_PAGES_TO_DETECT_DOCUMENT_TYPE=5
