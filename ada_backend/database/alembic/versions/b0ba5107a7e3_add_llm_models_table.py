"""add llm models table

Revision ID: b0ba5107a7e3
Revises: 8729faf18d1c
Create Date: 2025-11-13 10:51:54.913356

"""

from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision: str = "b0ba5107a7e3"
down_revision: Union[str, None] = "8729faf18d1c"
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table(
        "llm_model",
        sa.Column("id", sa.UUID(), server_default=sa.text("gen_random_uuid()"), nullable=False),
        sa.Column("name", sa.String(), nullable=False),
        sa.Column("description", sa.Text(), nullable=True),
        sa.Column("provider", sa.String(), nullable=False),
        sa.Column("reference", sa.String(), nullable=True),
        sa.Column("model_capacity", postgresql.JSONB(astext_type=sa.Text()), nullable=True),
        sa.Column("created_at", sa.DateTime(timezone=True), server_default=sa.text("now()"), nullable=True),
        sa.Column("updated_at", sa.DateTime(timezone=True), server_default=sa.text("now()"), nullable=True),
        sa.PrimaryKeyConstraint("id"),
    )
    op.create_index(op.f("ix_llm_model_id"), "llm_model", ["id"], unique=False)
    llm_models_table = sa.table(
        "llm_model",
        sa.column("name", sa.String()),
        sa.column("description", sa.Text()),
        sa.column("provider", sa.String()),
        sa.column("reference", sa.String()),
        sa.column("model_capacity", postgresql.JSONB(astext_type=sa.Text())),
    )
    op.bulk_insert(
        llm_models_table,
        [
            {
                "name": "GPT-5",
                "description": None,
                "provider": "openai",
                "reference": "openai:gpt-5",
                "model_capacity": [
                    "completion",
                    "file",
                    "image",
                    "constrained_output",
                    "function_calling",
                    "web_search",
                    "reasoning",
                ],
            },
            {
                "name": "GPT-5 Nano",
                "description": None,
                "provider": "openai",
                "reference": "openai:gpt-5-nano",
                "model_capacity": [
                    "completion",
                    "file",
                    "image",
                    "constrained_output",
                    "function_calling",
                    "web_search",
                    "reasoning",
                ],
            },
            {
                "name": "GPT-5 Mini",
                "description": None,
                "provider": "openai",
                "reference": "openai:gpt-5-mini",
                "model_capacity": [
                    "completion",
                    "file",
                    "image",
                    "constrained_output",
                    "function_calling",
                    "web_search",
                    "reasoning",
                ],
            },
            {
                "name": "GPT-4.1",
                "description": None,
                "provider": "openai",
                "reference": "openai:gpt-4.1",
                "model_capacity": [
                    "completion",
                    "file",
                    "image",
                    "constrained_output",
                    "function_calling",
                    "web_search",
                ],
            },
            {
                "name": "GPT-4.1 Mini",
                "description": None,
                "provider": "openai",
                "reference": "openai:gpt-4.1-mini",
                "model_capacity": [
                    "completion",
                    "file",
                    "image",
                    "constrained_output",
                    "function_calling",
                    "web_search",
                ],
            },
            {
                "name": "GPT-4.1 Nano",
                "description": None,
                "provider": "openai",
                "reference": "openai:gpt-4.1-nano",
                "model_capacity": [
                    "completion",
                    "image",
                    "file",
                    "constrained_output",
                    "function_calling",
                ],
            },
            {
                "name": "GPT-4o",
                "description": None,
                "provider": "openai",
                "reference": "openai:gpt-4o",
                "model_capacity": [
                    "completion",
                    "image",
                    "file",
                    "constrained_output",
                    "function_calling",
                    "web_search",
                ],
            },
            {
                "name": "GPT-4o Mini",
                "description": None,
                "provider": "openai",
                "reference": "openai:gpt-4o-mini",
                "model_capacity": [
                    "completion",
                    "image",
                    "file",
                    "constrained_output",
                    "function_calling",
                    "web_search",
                ],
            },
            {
                "name": "Gemini 2.5 Pro",
                "description": None,
                "provider": "google",
                "reference": "google:gemini-2.5-pro-preview-06-05",
                "model_capacity": [
                    "completion",
                    "image",
                    "constrained_output",
                    "function_calling",
                ],
            },
            {
                "name": "Gemini 2.5 Flash",
                "description": None,
                "provider": "google",
                "reference": "google:gemini-2.5-flash-preview-05-20",
                "model_capacity": [
                    "completion",
                    "image",
                    "constrained_output",
                    "function_calling",
                ],
            },
            {
                "name": "Gemini 2.0 Flash",
                "description": None,
                "provider": "google",
                "reference": "google:gemini-2.0-flash",
                "model_capacity": [
                    "completion",
                    "image",
                    "constrained_output",
                    "function_calling",
                ],
            },
            {
                "name": "Gemini 2.0 Flash lite",
                "description": None,
                "provider": "google",
                "reference": "google:gemini-2.0-flash-lite",
                "model_capacity": [
                    "completion",
                    "image",
                    "constrained_output",
                    "function_calling",
                ],
            },
            {
                "name": "Llama 3.3 70B (Cerebras)",
                "description": None,
                "provider": "cerebras",
                "reference": "cerebras:llama-3.3-70b",
                "model_capacity": [
                    "completion",
                    "constrained_output",
                    "function_calling",
                ],
            },
            {
                "name": "Qwen 3 235B Instruct (Cerebras)",
                "description": None,
                "provider": "cerebras",
                "reference": "cerebras:qwen-3-235b-a22b-instruct-2507",
                "model_capacity": [
                    "completion",
                    "constrained_output",
                    "function_calling",
                ],
            },
            {
                "name": "Qwen 3 32B (Cerebras)",
                "description": None,
                "provider": "cerebras",
                "reference": "cerebras:qwen-3-32b",
                "model_capacity": [
                    "completion",
                    "constrained_output",
                    "function_calling",
                    "reasoning",
                ],
            },
            {
                "name": "OpenAI GPT OSS (Cerebras)",
                "description": None,
                "provider": "cerebras",
                "reference": "cerebras:gpt-oss-120b",
                "model_capacity": [
                    "completion",
                    "constrained_output",
                    "function_calling",
                ],
            },
            {
                "name": "Mistral Large 2411",
                "description": None,
                "provider": "mistral",
                "reference": "mistral:mistral-large-latest",
                "model_capacity": [
                    "completion",
                    "constrained_output",
                    "function_calling",
                ],
            },
            {
                "name": "Mistral Medium 2505",
                "description": None,
                "provider": "mistral",
                "reference": "mistral:mistral-medium-latest",
                "model_capacity": [
                    "completion",
                    "constrained_output",
                    "function_calling",
                ],
            },
            {
                "name": "Mistral OCR 2505",
                "description": None,
                "provider": "mistral",
                "reference": "mistral:mistral-ocr-latest",
                "model_capacity": [
                    "ocr",
                ],
            },
            {
                "name": "Text Embedding 3 Large",
                "description": None,
                "provider": "openai",
                "reference": "openai:text-embedding-3-large",
                "model_capacity": [
                    "embedding",
                ],
            },
        ],
    )
    # ### end Alembic commands ###


def downgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_index(op.f("ix_llm_model_id"), table_name="llm_model")
    op.drop_table("llm_model")
    # ### end Alembic commands ###
